{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_07_19_크롤링_데이터_저장하기(DataFrame,_img) (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loPra1EPLwp3"
      },
      "source": [
        "# \"2021년 여름방학 특강 크롤링 데이터 저장하기\"\n",
        "> \"이미지(img), 데이터(DataFrame) 등 외부 데이터 저장하기\"\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: kang a-hyeon\n",
        "- categories: [crawling]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qv1_yCfO_eq"
      },
      "source": [
        "## 크롤링 기본 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K-0nd2qcepE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "1ac7691f-16e7-45b1-c84d-587567a3db2c"
      },
      "source": [
        "# 실행시키지 마세요.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = '수정필요'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "datagroup = soup.select('수정필요') # 클래스 '.' , 아이디 '#' \n",
        "for no, data in enumerate(datagroup, 1):\n",
        "    print(no, data.text)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MissingSchema",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-aa4c6a56769d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'수정필요'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '수정필요': No schema supplied. Perhaps you meant http://수정필요?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvURUCJTg4po"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://ridibooks.com/category/bestsellers/2200'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "datagroup = soup.select('.title_text') # 클래스 '.' , 아이디 '#' \n",
        "for no, data in enumerate(datagroup, 1):\n",
        "    print(no, data.text.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xRgxKdpOzuh"
      },
      "source": [
        "## 이미지 크롤링 데이터 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1i25gR6ivtj"
      },
      "source": [
        "import shutil # 고수준의 파일연산 라이브러리\n",
        "import requests # request를 보낼 수 있는 라이브러리\n",
        "\n",
        "url = 'https://img.ridicdn.net/cover/194000109/xxlarge#1'\n",
        "r = requests.get(url, stream=True)\n",
        "with open('sample.jpg', 'wb') as f:\n",
        "    r.raw.decode_content = True\n",
        "    shutil.copyfileobj(r.raw, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VobBPnUY21FI"
      },
      "source": [
        "# https://img.ridicdn.net/cover/194000109/xxlarge#1\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "r = requests.get('https://img.ridicdn.net/cover/194000109/xxlarge#1', stream=True)\n",
        "if r.status_code == 200:\n",
        "    with open('test.jpg', 'wb') as f:\n",
        "        for data in r.iter_content(1024):\n",
        "            f.write(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdjmuG-pO5Mr"
      },
      "source": [
        "## 크롤링 데이터 홈페이지로 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMOwf_A6jNcN"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://ridibooks.com/category/bestsellers/2200'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "datagroup = soup.select('.thumbnail') # 클래스 '.' , 아이디 '#' \n",
        "\n",
        "for data in datagroup:\n",
        "    print('https:' + data['data-src'][:-7] + 'xxlarge#1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PtGSzxemYKA"
      },
      "source": [
        "'https:' + datagroup[0]['data-src']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7QUcmyKn8iM"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://ridibooks.com/category/bestsellers/2200'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "책순위 = []\n",
        "책제목 = []\n",
        "책이미지 = []\n",
        "\n",
        "책제목크롤링 = soup.select('.title_text')\n",
        "for no, data in enumerate(책제목크롤링, 1):\n",
        "    책순위.append(no)\n",
        "    책제목.append(data.text.strip())\n",
        "\n",
        "책이미지크롤링 = soup.select('.thumbnail') \n",
        "\n",
        "for data in 책이미지크롤링:\n",
        "    책이미지.append('https:' + data['data-src'][:-7] + 'xxlarge#1')\n",
        "\n",
        "데이터 = {\n",
        "    '책순위':책순위,\n",
        "    '책제목':책제목,\n",
        "    '책이미지':책이미지\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNTrVGlLn97T"
      },
      "source": [
        "데이터 = pd.DataFrame(데이터)\n",
        "데이터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywcc1-6fpynp"
      },
      "source": [
        "def 이미지양식변환(path):\n",
        "    return '<img src=\"'+ path + '\" width=\"100px\" >'\n",
        "\n",
        "데이터.to_html('index.html', escape=False, formatters=dict(책이미지=이미지양식변환))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ4DZu5Vp-Nq"
      },
      "source": [
        "#이렇게 하지 마세요.\n",
        "s = ''\n",
        "for i, j, k in zip(책순위, 책제목, 책이미지):\n",
        "    s += f'<tr>\\\n",
        "                <td>{i}</td>\\\n",
        "                <td>{j}</td>\\\n",
        "                <td><img src={k}></td>\\\n",
        "           </tr>'\n",
        "s = '<table>' + s + '</table>'\n",
        "with open(\"노동.html\", \"w\") as f:\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAofnqivPFcv"
      },
      "source": [
        "## 크롤링 이미지 데이터 파일로 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyFNH-bfOrh0"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import shutil # 고수준의 파일연산 라이브러리\n",
        "\n",
        "url = 'https://ridibooks.com/category/bestsellers/2200'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "datagroup = soup.select('.thumbnail') # 클래스 '.' , 아이디 '#' \n",
        "\n",
        "for data in datagroup:\n",
        "    print('https:' + data['data-src'][:-7] + 'xxlarge#1')\n",
        "\n",
        "'''\n",
        "url = 'https://img.ridicdn.net/cover/194000109/xxlarge#1'\n",
        "r = requests.get(url, stream=True)\n",
        "with open('sample.jpg', 'wb') as f:\n",
        "    r.raw.decode_content = True\n",
        "    shutil.copyfileobj(r.raw, f)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09Kb5WZdPgy3"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import shutil # 고수준의 파일연산 라이브러리\n",
        "\n",
        "url = 'https://ridibooks.com/category/bestsellers/2200'\n",
        "response = requests.get(url)\n",
        "response.encoding = 'utf-8'\n",
        "html = response.text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "datagroup = soup.select('.thumbnail') # 클래스 '.' , 아이디 '#' \n",
        "filename = 0\n",
        "\n",
        "for data in datagroup:\n",
        "    url = 'https:' + data['data-src'][:-7] + 'xxlarge#1'\n",
        "    r = requests.get(url, stream=True)\n",
        "    #성산일출봉 폴더에 다운로드 받아 저장합니다.\n",
        "    with open('성산일출봉/' + str(filename) + '.jpg', 'wb') as f:\n",
        "        r.raw.decode_content = True\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    filename += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}